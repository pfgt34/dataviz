"""
API FastAPI pour l'analyse du dataset Superstore
ðŸŽ¯ Niveau dÃ©butant - Code simple et bien commentÃ©
ðŸ“Š Tous les KPI e-commerce implÃ©mentÃ©s
"""

from fastapi import FastAPI, Query, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from typing import Optional, List, Dict, Any
from datetime import datetime
import pandas as pd
from pydantic import BaseModel
import logging

# Configuration du logger pour faciliter le dÃ©bogage
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialisation de l'application FastAPI
app = FastAPI(
    title="Superstore BI API",
    description="API d'analyse Business Intelligence pour le dataset Superstore",
    version="1.0.0",
    docs_url="/docs",  # Documentation Swagger accessible via /docs
    redoc_url="/redoc"  # Documentation ReDoc accessible via /redoc
)

# Configuration CORS pour permettre les appels depuis Streamlit
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En production, spÃ©cifier l'URL exacte de Streamlit
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# === CHARGEMENT DES DONNÃ‰ES ===

# URL du dataset Superstore sur GitHub
DATASET_URL = "https://raw.githubusercontent.com/leonism/sample-superstore/master/data/superstore.csv"

def load_data() -> pd.DataFrame:
    """
    Charge le dataset Superstore depuis GitHub
    Nettoie et prÃ©pare les donnÃ©es pour l'analyse
    
    Returns:
        pd.DataFrame: Dataset nettoyÃ© et prÃªt Ã  l'emploi
    """
    try:
        logger.info(f"Chargement du dataset depuis {DATASET_URL}")
        
        # Lecture du CSV
        df = pd.read_csv(DATASET_URL, encoding='latin-1')
        
        # Nettoyage des noms de colonnes (suppression espaces)
        df.columns = df.columns.str.strip()
        
        # Conversion des dates au format datetime
        df['Order Date'] = pd.to_datetime(df['Order Date'])
        df['Ship Date'] = pd.to_datetime(df['Ship Date'])
        
        # Suppression des lignes avec valeurs manquantes critiques
        df = df.dropna(subset=['Order ID', 'Customer ID', 'Sales'])
        
        logger.info(f"âœ… Dataset chargÃ© : {len(df)} commandes")
        return df
        
    except Exception as e:
        logger.error(f"âŒ Erreur lors du chargement des donnÃ©es : {e}")
        raise HTTPException(status_code=500, detail=f"Erreur de chargement : {str(e)}")

# Chargement des donnÃ©es au dÃ©marrage de l'application
df = load_data()

# === MODÃˆLES PYDANTIC (pour la validation des rÃ©ponses) ===

class KPIGlobaux(BaseModel):
    """ModÃ¨le pour les KPI globaux"""
    ca_total: float
    nb_commandes: int
    nb_clients: int
    panier_moyen: float
    quantite_vendue: int
    profit_total: float
    marge_moyenne: float

class ProduitTop(BaseModel):
    """ModÃ¨le pour les produits top performers"""
    produit: str
    categorie: str
    ca: float
    quantite: int
    profit: float

class CategoriePerf(BaseModel):
    """ModÃ¨le pour la performance par catÃ©gorie"""
    categorie: str
    ca: float
    profit: float
    nb_commandes: int
    marge_pct: float

# === FONCTIONS UTILITAIRES ===

def filtrer_dataframe(
    df: pd.DataFrame,
    date_debut: Optional[str] = None,
    date_fin: Optional[str] = None,
    categorie: Optional[str] = None,
    region: Optional[str] = None,
    segment: Optional[str] = None
) -> pd.DataFrame:
    """
    Applique les filtres sur le dataframe
    
    Args:
        df: DataFrame source
        date_debut: Date de dÃ©but (YYYY-MM-DD)
        date_fin: Date de fin (YYYY-MM-DD)
        categorie: CatÃ©gorie de produit
        region: RÃ©gion gÃ©ographique
        segment: Segment client
        
    Returns:
        pd.DataFrame: DataFrame filtrÃ©
    """
    df_filtered = df.copy()
    
    # Filtre par date
    if date_debut:
        df_filtered = df_filtered[df_filtered['Order Date'] >= date_debut]
    if date_fin:
        df_filtered = df_filtered[df_filtered['Order Date'] <= date_fin]
    
    # Filtre par catÃ©gorie
    if categorie and categorie != "Toutes":
        df_filtered = df_filtered[df_filtered['Category'] == categorie]
    
    # Filtre par rÃ©gion
    if region and region != "Toutes":
        df_filtered = df_filtered[df_filtered['Region'] == region]
    
    # Filtre par segment
    if segment and segment != "Tous":
        df_filtered = df_filtered[df_filtered['Segment'] == segment]
    
    return df_filtered

# === ENDPOINTS API ===

@app.get("/", tags=["Info"])
def root():
    """
    Endpoint racine - Informations sur l'API
    """
    return {
        "message": "ðŸ›’ API Superstore BI",
        "version": "1.0.0",
        "dataset": "Sample Superstore",
        "nb_lignes": len(df),
        "periode": {
            "debut": df['Order Date'].min().strftime('%Y-%m-%d'),
            "fin": df['Order Date'].max().strftime('%Y-%m-%d')
        },
        "endpoints": {
            "documentation": "/docs",
            "kpi_globaux": "/kpi/globaux",
            "top_produits": "/kpi/produits/top",
            "categories": "/kpi/categories",
            "evolution_temporelle": "/kpi/temporel",
            "performance_geo": "/kpi/geographique",
            "analyse_clients": "/kpi/clients"
        }
    }

@app.get("/kpi/globaux", response_model=KPIGlobaux, tags=["KPI"])
def get_kpi_globaux(
    date_debut: Optional[str] = Query(None, description="Date dÃ©but (YYYY-MM-DD)"),
    date_fin: Optional[str] = Query(None, description="Date fin (YYYY-MM-DD)"),
    categorie: Optional[str] = Query(None, description="CatÃ©gorie produit"),
    region: Optional[str] = Query(None, description="RÃ©gion"),
    segment: Optional[str] = Query(None, description="Segment client")
):
    """
    ðŸ“Š KPI GLOBAUX
    
    Calcule les indicateurs clÃ©s globaux :
    - Chiffre d'affaires total
    - Nombre de commandes
    - Nombre de clients uniques
    - Panier moyen
    - QuantitÃ© totale vendue
    - Profit total
    - Marge moyenne (%)
    """
    # Application des filtres
    df_filtered = filtrer_dataframe(df, date_debut, date_fin, categorie, region, segment)
    
    # Calcul des KPI
    ca_total = df_filtered['Sales'].sum()
    nb_commandes = df_filtered['Order ID'].nunique()
    nb_clients = df_filtered['Customer ID'].nunique()
    panier_moyen = ca_total / nb_commandes if nb_commandes > 0 else 0
    quantite_vendue = int(df_filtered['Quantity'].sum())
    profit_total = df_filtered['Profit'].sum()
    marge_moyenne = (profit_total / ca_total * 100) if ca_total > 0 else 0
    
    return KPIGlobaux(
        ca_total=round(ca_total, 2),
        nb_commandes=nb_commandes,
        nb_clients=nb_clients,
        panier_moyen=round(panier_moyen, 2),
        quantite_vendue=quantite_vendue,
        profit_total=round(profit_total, 2),
        marge_moyenne=round(marge_moyenne, 2)
    )

@app.get("/kpi/produits/top", tags=["KPI"])
def get_top_produits(
    limite: int = Query(10, ge=1, le=50, description="Nombre de produits Ã  retourner"),
    tri_par: str = Query("ca", regex="^(ca|profit|quantite)$", description="CritÃ¨re de tri")
):
    """
    ðŸ† TOP PRODUITS
    
    Retourne les meilleurs produits selon le critÃ¨re choisi :
    - ca : Chiffre d'affaires
    - profit : Profit
    - quantite : QuantitÃ© vendue
    """
    # AgrÃ©gation par produit
    produits = df.groupby(['Product Name', 'Category']).agg({
        'Sales': 'sum',
        'Quantity': 'sum',
        'Profit': 'sum'
    }).reset_index()
    
    # Tri selon le critÃ¨re
    if tri_par == "ca":
        produits = produits.sort_values('Sales', ascending=False)
    elif tri_par == "profit":
        produits = produits.sort_values('Profit', ascending=False)
    else:  # quantite
        produits = produits.sort_values('Quantity', ascending=False)
    
    # SÃ©lection du top
    top = produits.head(limite)
    
    # Formatage de la rÃ©ponse
    result = []
    for _, row in top.iterrows():
        result.append({
            "produit": row['Product Name'],
            "categorie": row['Category'],
            "ca": round(row['Sales'], 2),
            "quantite": int(row['Quantity']),
            "profit": round(row['Profit'], 2)
        })
    
    return result

@app.get("/kpi/categories", tags=["KPI"])
def get_performance_categories():
    """
    ðŸ“¦ PERFORMANCE PAR CATÃ‰GORIE
    
    Analyse la performance de chaque catÃ©gorie :
    - CA total
    - Profit
    - Nombre de commandes
    - Marge (%)
    """
    # AgrÃ©gation par catÃ©gorie
    categories = df.groupby('Category').agg({
        'Sales': 'sum',
        'Profit': 'sum',
        'Order ID': 'nunique'
    }).reset_index()
    
    # Calcul de la marge
    categories['marge_pct'] = (categories['Profit'] / categories['Sales'] * 100).round(2)
    
    # Renommage des colonnes
    categories.columns = ['categorie', 'ca', 'profit', 'nb_commandes', 'marge_pct']
    
    # Tri par CA dÃ©croissant
    categories = categories.sort_values('ca', ascending=False)
    
    return categories.to_dict('records')

@app.get("/kpi/temporel", tags=["KPI"])
def get_evolution_temporelle(
    periode: str = Query('mois', regex='^(jour|mois|annee)$', description="GranularitÃ© temporelle")
):
    """
    ðŸ“ˆ Ã‰VOLUTION TEMPORELLE
    
    Analyse l'Ã©volution du CA, profit et commandes dans le temps
    GranularitÃ©s disponibles : jour, mois, annee
    """
    df_temp = df.copy()
    
    # CrÃ©ation de la colonne pÃ©riode selon la granularitÃ©
    if periode == 'jour':
        df_temp['periode'] = df_temp['Order Date'].dt.strftime('%Y-%m-%d')
    elif periode == 'mois':
        df_temp['periode'] = df_temp['Order Date'].dt.strftime('%Y-%m')
    else:  # annee
        df_temp['periode'] = df_temp['Order Date'].dt.strftime('%Y')
    
    # AgrÃ©gation
    temporal = df_temp.groupby('periode').agg({
        'Sales': 'sum',
        'Profit': 'sum',
        'Order ID': 'nunique',
        'Quantity': 'sum'
    }).reset_index()
    
    temporal.columns = ['periode', 'ca', 'profit', 'nb_commandes', 'quantite']
    
    # Tri chronologique
    temporal = temporal.sort_values('periode')
    
    return temporal.to_dict('records')

@app.get("/kpi/geographique", tags=["KPI"])
def get_performance_geographique():
    """
    ðŸŒ PERFORMANCE GÃ‰OGRAPHIQUE
    
    Analyse la performance par rÃ©gion :
    - CA par rÃ©gion
    - Profit par rÃ©gion
    - Nombre de clients
    - Nombre de commandes
    """
    geo = df.groupby('Region').agg({
        'Sales': 'sum',
        'Profit': 'sum',
        'Customer ID': 'nunique',
        'Order ID': 'nunique'
    }).reset_index()
    
    geo.columns = ['region', 'ca', 'profit', 'nb_clients', 'nb_commandes']
    geo = geo.sort_values('ca', ascending=False)
    
    return geo.to_dict('records')

@app.get("/kpi/clients", tags=["KPI"])
def get_analyse_clients(
    limite: int = Query(10, ge=1, le=100, description="Nombre de top clients")
):
    """
    ðŸ‘¥ ANALYSE CLIENTS
    
    Retourne :
    - Top clients par CA
    - Statistiques de rÃ©currence
    - Analyse par segment
    """
    # Top clients
    clients = df.groupby('Customer ID').agg({
        'Sales': 'sum',
        'Profit': 'sum',
        'Order ID': 'nunique',
        'Customer Name': 'first'
    }).reset_index()
    
    clients.columns = ['customer_id', 'ca_total', 'profit_total', 'nb_commandes', 'nom']
    clients['valeur_commande_moy'] = (clients['ca_total'] / clients['nb_commandes']).round(2)
    
    top_clients = clients.sort_values('ca_total', ascending=False).head(limite)
    
    # Statistiques de rÃ©currence
    recurrence = {
        "clients_1_achat": len(clients[clients['nb_commandes'] == 1]),
        "clients_recurrents": len(clients[clients['nb_commandes'] > 1]),
        "nb_commandes_moyen": round(clients['nb_commandes'].mean(), 2),
        "total_clients": len(clients)
    }
    
    # Analyse par segment
    segments = df.groupby('Segment').agg({
        'Sales': 'sum',
        'Profit': 'sum',
        'Customer ID': 'nunique'
    }).reset_index()
    segments.columns = ['segment', 'ca', 'profit', 'nb_clients']
    
    return {
        "top_clients": top_clients.to_dict('records'),
        "recurrence": recurrence,
        "segments": segments.to_dict('records')
    }

@app.get("/filters/valeurs", tags=["Filtres"])
def get_valeurs_filtres():
    """
    ðŸŽ¯ VALEURS POUR LES FILTRES
    
    Retourne toutes les valeurs uniques disponibles pour les filtres
    """
    return {
        "categories": sorted(df['Category'].unique().tolist()),
        "regions": sorted(df['Region'].unique().tolist()),
        "segments": sorted(df['Segment'].unique().tolist()),
        "etats": sorted(df['State'].unique().tolist()),
        "plage_dates": {
            "min": df['Order Date'].min().strftime('%Y-%m-%d'),
            "max": df['Order Date'].max().strftime('%Y-%m-%d')
        }
    }

@app.get("/data/commandes", tags=["DonnÃ©es brutes"])
def get_commandes(
    limite: int = Query(100, ge=1, le=1000),
    offset: int = Query(0, ge=0)
):
    """
    ðŸ“‹ DONNÃ‰ES BRUTES
    
    Retourne les commandes brutes avec pagination
    """
    total = len(df)
    commandes = df.iloc[offset:offset+limite]
    
    # Conversion des dates en string pour JSON
    commandes_dict = commandes.copy()
    commandes_dict['Order Date'] = commandes_dict['Order Date'].dt.strftime('%Y-%m-%d')
    commandes_dict['Ship Date'] = commandes_dict['Ship Date'].dt.strftime('%Y-%m-%d')
    
    return {
        "total": total,
        "limite": limite,
        "offset": offset,
        "data": commandes_dict.to_dict('records')
    }

# === DÃ‰MARRAGE DU SERVEUR ===

if __name__ == "__main__":
    import uvicorn
    print("ðŸš€ DÃ©marrage de l'API Superstore BI sur http://localhost:8000")
    print("ðŸ“š Documentation disponible sur http://localhost:8000/docs")
    uvicorn.run(app, host="0.0.0.0", port=8000)